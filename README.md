import streamlit as st
from llm_backend import process_query

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø©
st.set_page_config(page_title="Baqit Hub", page_icon="icon.png", layout="wide")

# ØªØ­Ù…ÙŠÙ„ ØµÙˆØ± Ø§Ù„Ø®Ù„ÙÙŠØ© ÙˆØ§Ù„Ø´Ø¹Ø§Ø± (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
st.markdown(
    """
    <style>
    body {
        background-color: #f5f5f0;
        font-family: 'Cairo', sans-serif;
    }
    .stChatMessage {
        direction: rtl;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù„ØºØ©
lang = st.sidebar.selectbox("Language / Ø§Ù„Ù„ØºØ©", ["English", "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"])

# Ø¹Ù†ÙˆØ§Ù† Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
st.image("logo.png", width=120)
st.title("ğŸ‡¸ğŸ‡¦ Baqit Hub â€“ Ù…Ù†ØµØ© ØªØ¹Ù„ÙŠÙ…ÙŠØ© Ø°ÙƒÙŠØ©")

# Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
if "messages" not in st.session_state:
    st.session_state.messages = []

# Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
if prompt := st.chat_input("Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§..." if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else "Type your question here..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)
import json
import subprocess

LLM_MODEL = "qwen2.5:14b"

# ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
with open("resources.json", "r", encoding="utf-8") as f:
    RESOURCES = json.load(f)

def detect_query_language(query: str) -> str:
    if any("\u0600" <= ch <= "\u06FF" for ch in query):
        return "ar"
    return "en"

def ask_llm_intent(query: str):
    """Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ollama Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…"""
    result = subprocess.run(
        ["ollama", "run", LLM_MODEL, query],
        capture_output=True,
        text=True
    )
    return result.stdout.strip()

def extract_resource_key(llm_response: str):
    """ÙŠØ¨Ø³Ø· Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙØªØ§Ø­ Ù…Ù† Ø±Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"""
    for res in RESOURCES:
        if res["title_en"].lower() in llm_response.lower() or res["title_ar"] in llm_response:
            return res
    return None

def build_response(resource, lang="en"):
    if not resource:
        return "âŒ Resource not found. Ø­Ø§ÙˆÙ„ ØµÙŠØ§ØºØ© Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ø´ÙƒÙ„ Ø£ÙˆØ¶Ø­." if lang == "ar" else "âŒ Resource not found. Please rephrase your query."

    if lang == "ar":
        return f"""
### {resource['title_ar']}
{resource['description_ar']}

**Ø§Ù„Ø®Ø·ÙˆØ§Øª:**
{resource['steps_ar']}

**Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª:**
{resource['requirements_ar']}

[Ø±Ø§Ø¨Ø· Ø±Ø³Ù…ÙŠ]({resource['official_link']})
"""
    else:
        return f"""
### {resource['title_en']}
{resource['description_en']}

**Steps:**
{resource['steps_en']}

**Requirements:**
{resource['requirements_en']}

[Official Link]({resource['official_link']})
"""

def process_query(query: str, lang: str):
    llm_response = ask_llm_intent(query)
    resource = extract_resource_key(llm_response)
    return build_response(resource, "ar" if lang == "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©" else "en")
[
  {
    "platform": "Qiyas",
    "category": "Testing",
    "title_ar": "Ø§Ù„ØªØ­Ø¶ÙŠØ± Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù‚Ø¯Ø±Ø§Øª",
    "title_en": "Qiyas Exam Preparation",
    "description_ar": "Ù…ÙˆØ§Ø±Ø¯ Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ ÙÙŠ Ø§Ù„ØªØ­Ø¶ÙŠØ± Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù‚Ø¯Ø±Ø§Øª.",
    "description_en": "Resources to help you prepare for Qiyas exam.",
    "steps_ar": "Ù¡. Ø³Ø¬Ù„ ÙÙŠ Ù…ÙˆÙ‚Ø¹ Ù‚ÙŠØ§Ø³\nÙ¢. Ø§Ø®ØªØ± Ù†ÙˆØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±\nÙ£. Ø§Ø·Ù„Ø¹ Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙˆØ§Ø¯ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ÙŠØ©",
    "steps_en": "1. Register on Qiyas website\n2. Select exam type\n3. Review training materials",
    "requirements_ar": "Ø­Ø³Ø§Ø¨ ÙÙŠ Ù…ÙˆÙ‚Ø¹ Ù‚ÙŠØ§Ø³",
    "requirements_en": "Qiyas account",
    "official_link": "https://www.qiyas.sa"
  },
  {
    "platform": "Coursera",
    "category": "Courses",
    "title_ar": "ÙƒÙˆØ±Ø³ Ø¨Ø±Ù…Ø¬Ø© Ø¨Ø§ÙŠØ«ÙˆÙ†",
    "title_en": "Python Programming Course",
    "description_ar": "ØªØ¹Ù„Ù… Ø£Ø³Ø§Ø³ÙŠØ§Øª Ù„ØºØ© Ø¨Ø§ÙŠØ«ÙˆÙ† Ø¹Ø¨Ø± ÙƒÙˆØ±Ø³ ØªÙØ§Ø¹Ù„ÙŠ.",
    "description_en": "Learn Python basics through an interactive course.",
    "steps_ar": "Ù¡. Ø³Ø¬Ù„ ÙÙŠ ÙƒÙˆØ±Ø³ÙŠØ±Ø§\nÙ¢. Ø§Ø¨Ø­Ø« Ø¹Ù† Python\nÙ£. Ø§Ø¨Ø¯Ø£ Ø§Ù„ÙƒÙˆØ±Ø³",
    "steps_en": "1. Sign up on Coursera\n2. Search for Python\n3. Start the course",
    "requirements_ar": "Ø¨Ø±ÙŠØ¯ Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ ÙØ¹Ø§Ù„",
    "requirements_en": "Valid email address",
    "official_link": "https://www.coursera.org"
  }
]

    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø¹Ø¨Ø± LLM
    response = process_query(prompt, lang)

    st.session_state.messages.append({"role": "assistant", "content": response})
    with st.chat_message("assistant"):
        st.markdown(response)
